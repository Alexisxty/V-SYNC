# V-SYNC 全局配置（不写入敏感信息）

api:
  openai:
    base_url: "https://api.aiserverai.online/v1"
  gemini:
    base_url: "https://api.aiserverai.online"

runtime:
  max_retries: 5
  request_delay: 0.0
  gpu_ids: []
  frame_interval_sec: 1
  max_frames: 8

models:
  defaults:
    temperature: 0.0
    top_p: 1.0
    max_tokens: 256
  gpt4o:
    model_name: "gpt-4o"
    max_tokens: 200
    temperature: 0.1
  gemini_2_5_flash:
    model_name: "gemini-2.5-flash"
    max_tokens: 9000
    temperature: 0.1
  gemini_2_5_pro:
    model_name: "gemini-2.5-pro"
    max_tokens: 9000
    temperature: 0.1
  qwen2_5_omni:
    model_path: "/publicssd/xty/models/Qwen2.5-Omni-7B"
    max_tokens: 256
    temperature: 0.1
    use_audio_in_video: true
    num_video_frames: 256
    gpu_ids: [3]
    host: "0.0.0.0"
    port: 5089
    server_url: "http://127.0.0.1:5089"
    user_prompt: ""
  qwen3_omni:
    model_path: "/publicssd/xty/models/Qwen3-Omni-30B-A3B-Instruct"
    max_tokens: 256
    temperature: 0.1
    use_audio_in_video: true
    num_video_frames: 256
    gpu_ids: [6, 7]
    host: "0.0.0.0"
    port: 5090
    judge_model_path: ""
    server_url: "http://127.0.0.1:5090"
    user_prompt: ""
  qwen3_omni_thinking:
    model_path: "/publicssd/xty/models/Qwen3-Omni-30B-A3B-Thinking"
    max_tokens: 256
    temperature: 0.1
    use_audio_in_video: true
    num_video_frames: 256
    gpu_ids: [3,4,5,6]
    host: "0.0.0.0"
    port: 5091
    server_url: "http://127.0.0.1:5091"
    user_prompt: ""
  miniomni_2:
    model_path: "/publicssd/xty/models/mini-omni2"
    temperature: 0.1
    top_p: 1.0
    use_audio_in_video: true
    num_video_frames: 1  # only 1 frame (miniomni_2 currently uses single-frame + audio)
    gpu_ids: [6]
    host: "0.0.0.0"
    port: 5092
    server_url: "http://127.0.0.1:5092"
    user_prompt: ""
  omnivinci:
    model_path: "/publicssd/xty/models/omnivinci"
    max_new_tokens: 4096
    use_audio_in_video: true
    num_video_frames: 256
    gpu_ids: [6, 7]
    host: "0.0.0.0"
    port: 5091
    server_url: "http://127.0.0.1:5091"
    user_prompt: ""
  vita_1_5:
    model_path: "/publicssd/xty/models/VITA-1.5"
    max_tokens: 256
    gpu_ids: [3]
    host: "0.0.0.0"
    port: 5093
    server_url: "http://127.0.0.1:5093"
    user_prompt: ""
  baichuan_omni_1_5:
    model_path: "/publicssd/xty/models/Baichuan-Omni-1d5"
    max_tokens: 256
    use_audio_in_video: false
    # Baichuan-Omni 原生音频最大 30s（模型内限制），这里统一使用 ASR 文本输入
    gpu_ids: [3, 4,5,6]
    host: "0.0.0.0"
    port: 5094
    server_url: "http://127.0.0.1:5094"
    user_prompt: ""

prompts:
  answer_format: "Answer ONLY with the option letter (A, B, C, or D). Do not include any other text."

benchmark:
  level1:
    model: ""
    dataset_path: ""
    video_dir: ""
    output_dir: ""
    output_pattern: "results_{model}_level1.json"
    log_dir: ""
    modality: "avt"  # avt(音频+视频), vt(仅视频), at(仅音频)
    system_prompt: "You are a precise video-audio reasoning assistant. You must answer ONLY with the option letter (A, B, C, or D)."
    user_prompt: "Please carefully analyze the video, paying attention to the temporal relationship between the audio and visual content."
    max_retries: 5
    retry_delay: 3
    num_workers: 8
  level2:
    model: ""
    dataset_path: ""
    video_dir: ""
    output_dir: ""
    output_pattern: "results_{model}_level2.json"
    log_dir: ""
    modality: "avt"
    system_prompt: ""
    user_prompt: ""
    max_retries: 5
    retry_delay: 3
    num_workers: 8
  level3:
    model: ""
    dataset_path: ""
    video_dir: ""
    output_dir: ""
    output_pattern: "results_{model}_level3.json"
    log_dir: ""
    modality: "avt"
    system_prompt: ""
    user_prompt: ""
    max_retries: 5
    retry_delay: 3
    num_workers: 8
